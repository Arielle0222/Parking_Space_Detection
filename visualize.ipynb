{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2개 카테고리 /4개 카테고리에 따른 각각의 이미지 segmentation 시각화 과정",
   "id": "c3b890cb42ad7a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 주차 공간 인식을 위한 Mask R-CNN 모델\n",
    "\n",
    "## 필요한 라이브러리 임포트\n",
    "\n",
    "먼저 필요한 라이브러리들을 임포트합니다.\n"
   ],
   "id": "83dcc96affde3f45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "id": "e13e3994fc6204e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## GPU 설정\n",
    "\n",
    "이 노트북은 GPU를 사용하여 모델을 학습 및 평가합니다. GPU가 사용 가능한 경우, GPU를 사용하도록 설정합니다.\n"
   ],
   "id": "cc25905f1f1f9758"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# GPU 사용 여부 설정\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ],
   "id": "8a05b10b8e315fe7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 모델 로드 함수\n",
    "\n",
    "이 함수는 사전 학습된 Mask R-CNN 모델을 로드하고, 주차 공간, 도로, 차량, 사람의 클래스를 포함한 커스텀 모델로 수정합니다.\n",
    "\n",
    "### 변수:\n",
    "- `num_classes`: 모델에서 예측할 클래스의 수입니다.\n",
    "- `weights_path`: 모델 가중치 파일의 경로입니다.\n"
   ],
   "id": "32fea78746de3d9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_model(num_classes, weights_path):\n",
    "    model = maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        model.roi_heads.mask_predictor.conv5_mask.in_channels, 256, num_classes)\n",
    "    model.load_state_dict(torch.load(weights_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n"
   ],
   "id": "ac62a6a583deca5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 이미지 전처리 함수\n",
    "\n",
    "이 함수는 이미지를 Tensor 형식으로 변환하여 모델에 입력할 수 있는 형태로 만들어줍니다.\n",
    "\n",
    "### 변수:\n",
    "- `train`: 학습 모드 여부를 나타냅니다. 여기서는 평가 모드로 사용됩니다.\n"
   ],
   "id": "57aaafb7757fdaa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(torchvision.transforms.ToTensor())\n",
    "    return torchvision.transforms.Compose(transforms)\n"
   ],
   "id": "92cc169946e0b884"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 예측 시각화 함수\n",
    "\n",
    "이 함수는 주어진 이미지에 대해 모델의 예측을 시각화하고, 주차 공간, 차량, 사람의 개수를 화면에 표시합니다.\n",
    "\n",
    "### 인자:\n",
    "- `model`: 학습된 Mask R-CNN 모델입니다.\n",
    "- `img_path`: 예측할 이미지의 경로입니다.\n",
    "- `device`: GPU 또는 CPU 장치를 나타냅니다.\n",
    "- `num_classes`: 모델에서 사용하는 클래스의 수입니다.\n"
   ],
   "id": "9dda30fe0d9618fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_predictions(model, img_path, device, num_classes):\n",
    "    model.eval()\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    transform = get_transform(train=False)\n",
    "    img_tensor = transform(img).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model([img_tensor])\n",
    "\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # 카테고리 이름 및 색상 정의 (1: 주차 공간, 2: 도로, 3: 사람, 4: 차량)\n",
    "    category_names = {1: \"Parking Space\", 2: \"Driveable Space\", 3: \"Person\", 4: \"Vehicle\"}\n",
    "    colors = {\n",
    "        1: (0, 255, 0),  # Parking Space: Green\n",
    "        2: (255, 0, 0),  # Driveable Space: Red\n",
    "        3: (255, 255, 0),  # Person: Yellow\n",
    "        4: (0, 0, 255)  # Vehicle: Blue\n",
    "    }\n",
    "\n",
    "    parking_space_count = 0\n",
    "    vehicle_count = 0\n",
    "    person_count = 0\n",
    "\n",
    "    for i in range(len(predictions[0]['masks'])):\n",
    "        score = predictions[0]['scores'][i].cpu().item()\n",
    "        label = predictions[0]['labels'][i].cpu().item()\n",
    "\n",
    "        if score > 0.6:  # Threshold\n",
    "            if label == 1:  # 주차 공간\n",
    "                parking_space_count += 1\n",
    "            elif label == 4 and num_classes > 3:  # 차량\n",
    "                vehicle_count += 1\n",
    "            elif label == 3 and num_classes > 3:  # 사람\n",
    "                person_count += 1\n",
    "\n",
    "            color = colors.get(label, (255, 255, 255))  # 카테고리 색상을 가져옴. 없으면 흰색으로 설정.\n",
    "\n",
    "            # Mask를 Segmentation 결과에 반영\n",
    "            mask = predictions[0]['masks'][i, 0].cpu().numpy()\n",
    "            mask = mask > 0.3\n",
    "            color_mask = np.zeros_like(img_np)\n",
    "            color_mask[mask] = color\n",
    "\n",
    "            img_np = cv2.addWeighted(img_np, 1, color_mask, 0.5, 0)\n",
    "\n",
    "    # 텍스트 가독성을 높이기 위한 반투명 박스 추가\n",
    "    box_coords = [(5, 5), (350, 120)]\n",
    "    cv2.rectangle(img_np, box_coords[0], box_coords[1], (0, 0, 0), cv2.FILLED)\n",
    "    alpha = 0.4  # 투명도 조절 (0: 투명, 1: 불투명)\n",
    "    img_np = cv2.addWeighted(img_np, alpha, img_np, 1 - alpha, 0, img_np)\n",
    "\n",
    "    # 텍스트 추가\n",
    "    cv2.putText(img_np, f\"Parking Spaces: {parking_space_count}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    if num_classes > 3:\n",
    "        cv2.putText(img_np, f\"Vehicles: {vehicle_count}\", (10, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(img_np, f\"Persons: {person_count}\", (10, 110),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img_np)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ],
   "id": "150098e4937b2e10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 모델 로드 및 예측 시각화 실행\n",
    "\n",
    "이제 모델을 로드하고, 예측을 시각화해보겠습니다. `num_classes`를 변경하여 필요한 클래스 수를 설정할 수 있습니다. 2로 하면(주차공간,도로) 4로하면 (기존 카테고리 + 사람,차량)\n"
   ],
   "id": "a9d1cd66f0585631"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 이미지 경로와 가중치 경로 설정\n",
    "img_path = \"path_to_your_image.jpg\"\n",
    "weights_path = \"path_to_your_weights.pth\"\n",
    "\n",
    "# 모델의 출력층을 커스터마이즈 (background + 4 classes)\n",
    "num_classes = 3  # background + 2 classes (Parking Space, Driveable Space)\n",
    "# num_classes = 5  # background + 4 classes (Parking Space, Driveable Space, Person, Vehicle)\n",
    "\n",
    "# 모델 로드\n",
    "model = load_model(num_classes, weights_path)\n",
    "\n",
    "# 예측 시각화 실행\n",
    "visualize_predictions(model, img_path, device, num_classes)\n"
   ],
   "id": "82758ea7446b8e17"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 동영상 추론 과정 을 위한 데이터 전처리 \n",
    "\n"
   ],
   "id": "c2ac6866990acca1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "동영상의 배속을 0.3으로 만들어서 segment의 변동성을 줄여주기 위해서 진행했습니다.\n",
    "이 과정을 진행 안할시에 너무 빨리 주차공간을 카운트하기 때문에 관찰이 힘들어서 이와같이 진행했습니다."
   ],
   "id": "ebd69cea17ee380e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import moviepy.video.fx.all as vfx\n",
    "# 원본 동영상 파일 경로\n",
    "input_file = r\"C:\\088.주차 공간 탐색을 위한 차량 관점 복합 데이터\\market.mp4\"\n",
    "# 변환된 동영상 파일 경로\n",
    "output_file = r\"C:\\088.주차 공간 탐색을 위한 차량 관점 복합 데이터\\market_0.3.mp4\"\n",
    "\n",
    "# 동영상 파일 로드\n",
    "clip = VideoFileClip(input_file)\n",
    "\n",
    "# 0.3배속으로 동영상 속도 변환\n",
    "slow_clip = clip.fx(vfx.speedx, 0.3)\n",
    "\n",
    "# 변환된 동영상을 파일로 저장\n",
    "slow_clip.write_videofile(output_file, codec=\"libx264\", audio_codec=\"aac\")"
   ],
   "id": "8a5e29fa7d784316"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Mask R-CNN을 이용한 주차 공간 및 도로 인식**\n",
    "Mask R-CNN을 이용하여 이미지 및 비디오에서 주차 공간과 도로를 인식하고, 주차 공간의 수를 계산하는 방법을 구현합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. 라이브러리 임포트 및 장치 설정**\n",
    "\n",
    "먼저, 필요한 라이브러리들을 임포트하고, GPU 사용을 설정합니다.\n"
   ],
   "id": "ef70fae6eb75edc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 라이브러리 임포트\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 장치 설정 (CUDA 사용 가능 시 GPU, 그렇지 않으면 CPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ],
   "id": "c6ae64efff421a6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## **2. Mask R-CNN 모델 불러오기 및 수정**\n",
    "\n",
    "이 함수는 사전 학습된 Mask R-CNN 모델을 불러오고, 사용자 정의 클래스로 수정합니다. 주차 공간 및 도로 클래스를 포함하여 모델을 학습시키기 위해 이 부분을 수정할 수 있습니다.\n",
    "    사전 학습된 Mask R-CNN 모델을 불러오고, 사용자 정의 클래스로 수정합니다.\n",
    "\n",
    "    Args:\n",
    "    - num_classes (int): 클래스의 수 (배경 포함).\n",
    "    - weights_path (str): 모델 가중치가 저장된 경로.\n",
    "\n",
    "    Returns:\n",
    "    - model (torch.nn.Module): 불러온 Mask R-CNN 모델."
   ],
   "id": "161ca1ffcc431337"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8d1883f01e7ad329"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_model(num_classes, weights_path):\n",
    "\n",
    "    # 사전 학습된 Mask R-CNN 모델 로드\n",
    "    model = maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    \n",
    "    # 클래스 예측기를 사용자 정의 클래스 수에 맞게 수정\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    # 마스크 예측기를 사용자 정의 클래스 수에 맞게 수정\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        model.roi_heads.mask_predictor.conv5_mask.in_channels, 256, num_classes)\n",
    "    \n",
    "    # 저장된 가중치 로드\n",
    "    model.load_state_dict(torch.load(weights_path))\n",
    "    \n",
    "    # 모델을 GPU 또는 CPU로 이동\n",
    "    model.to(device)\n",
    "    \n",
    "    # 평가 모드로 전환\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n"
   ],
   "id": "2cd6124abcd91beb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## **3. Intersection over Union (IoU) 계산**\n",
    "\n",
    "IoU는 두 개의 바운딩 박스 간의 겹치는 부분을 계산하여 얼마나 겹치는지를 나타내는 지표입니다. 이 함수는 IoU를 계산합니다.\n",
    "    두 개의 바운딩 박스 간의 IoU(Intersection over Union)를 계산합니다.\n",
    "\n",
    "    Args:\n",
    "    - box1 (list): 첫 번째 바운딩 박스.\n",
    "    - box2 (list): 두 번째 바운딩 박스.\n",
    "\n",
    "    Returns:\n",
    "    - iou (float): 계산된 IoU 값.\n"
   ],
   "id": "fc3f6ef566f8fca1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_iou(box1, box2):\n",
    "\n",
    "    # 두 박스 간의 교집합 영역 계산\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    # 교집합 면적 계산\n",
    "    inter_area = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
    "    \n",
    "    # 각 박스의 면적 계산\n",
    "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
    "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
    "\n",
    "    # IoU 계산\n",
    "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
    "    return iou\n"
   ],
   "id": "43b3fdff6f382241"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## **4. IoU를 기반으로 겹치는 박스 필터링**\n",
    "\n",
    "여러 바운딩 박스가 있을 때, 겹치는 박스를 제거하여 하나의 박스만 남기는 방법을 사용합니다. 이 함수는 IoU 임계값을 기준으로 겹치는 박스를 필터링합니다.\n",
    " \n",
    "    IoU 임계값을 기준으로 겹치는 바운딩 박스를 필터링합니다.\n",
    "\n",
    "    Args:\n",
    "    - boxes (list): 바운딩 박스 리스트.\n",
    "    - iou_threshold (float): IoU 임계값.\n",
    "\n",
    "    Returns:\n",
    "    - filtered_boxes (list): 필터링된 바운딩 박스 리스트.\n",
    "    \n"
   ],
   "id": "b57dd09ec1509dfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def filter_overlapping_boxes(boxes, iou_threshold=0.5):\n",
    "\n",
    "    filtered_boxes = []\n",
    "    for i, box in enumerate(boxes):\n",
    "        overlap = False\n",
    "        for j, kept_box in enumerate(filtered_boxes):\n",
    "            # 두 박스 간의 IoU가 임계값을 넘는 경우 겹침으로 판단\n",
    "            if calculate_iou(box, kept_box) > iou_threshold:\n",
    "                overlap = True\n",
    "                break\n",
    "        # 겹치지 않는 박스만 필터링된 리스트에 추가\n",
    "        if not overlap:\n",
    "            filtered_boxes.append(box)\n",
    "    return filtered_boxes\n"
   ],
   "id": "53e4c36d8440ef41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## **5. 각 프레임에서 예측 시각화**\n",
    "\n",
    "이 함수는 주어진 프레임에 대해 Mask R-CNN 모델을 사용하여 예측을 수행하고, 주차 공간의 수를 계산하며, 시각화된 결과를 반환합니다.\n",
    "\n",
    "    각 프레임에서 예측 결과를 시각화하고 주차 공간의 수를 계산합니다.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): Mask R-CNN 모델.\n",
    "    - frame (np.array): 비디오 프레임.\n",
    "\n",
    "    Returns:\n",
    "    - img_np (np.array): 예측이 시각화된 프레임.\n"
   ],
   "id": "21c204f8448dd3fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_predictions(model, frame):\n",
    "\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    img_tensor = transform(frame).to(device).unsqueeze(0)\n",
    "\n",
    "    # 모델 예측 수행\n",
    "    with torch.no_grad():\n",
    "        predictions = model(img_tensor)\n",
    "\n",
    "    img_np = np.array(frame)\n",
    "    category_names = {1: \"Parking Space\", 2: \"Driveable Space\"}  # 카테고리 이름 정의\n",
    "\n",
    "    parking_boxes = []\n",
    "    for i in range(len(predictions[0]['masks'])):\n",
    "        score = predictions[0]['scores'][i].cpu().item()\n",
    "        label = predictions[0]['labels'][i].cpu().item()\n",
    "\n",
    "        if score > 0.8:  # 신뢰도 임계값 확인\n",
    "            box = predictions[0]['boxes'][i].cpu().numpy().astype(int)\n",
    "            mask = predictions[0]['masks'][i, 0].cpu().numpy()\n",
    "            mask = mask > 0.3  # 마스크 임계값 적용\n",
    "            color = np.zeros_like(img_np)\n",
    "\n",
    "            if label == 1:  # 주차 공간인 경우\n",
    "                color[mask] = [0, 255, 0]  # 초록색으로 표시\n",
    "                parking_boxes.append(box)\n",
    "            elif label == 2:  # 도로 공간인 경우\n",
    "                color[mask] = [255, 0, 0]  # 파란색으로 표시\n",
    "\n",
    "            img_np = cv2.addWeighted(img_np, 1, color, 0.5, 0)\n",
    "            \n",
    "            # 객체의 신뢰도 출력\n",
    "            text = f\"{category_names[label]}: {score * 100:.2f}%\"\n",
    "            cv2.putText(img_np, text, (box[0], box[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "    # 겹치는 주차 공간 박스를 필터링\n",
    "    filtered_parking_boxes = filter_overlapping_boxes(parking_boxes)\n",
    "\n",
    "    # 주차 공간 수를 화면에 표시\n",
    "    parking_spaces = len(filtered_parking_boxes)\n",
    "    cv2.putText(img_np, f\"Parking Spaces: {parking_spaces}\", (10, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    return img_np\n"
   ],
   "id": "522b2c6e9c09bb35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## **6. 비디오 처리**\n",
    "\n",
    "이 함수는 비디오 파일을 프레임 단위로 처리하여, 각 프레임에서 주차 공간을 계산하고 예측 결과를 시각화한 후, 결과 비디오를 저장합니다.\n"
   ],
   "id": "1162ae096d331cde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_video(video_path, model, output_path, playback_speed=0.3):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    for _ in tqdm(range(total_frames), desc=\"Processing video\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        result_frame = visualize_predictions(model, frame)\n",
    "\n",
    "        # Adjust FPS to match the playback speed\n",
    "        adjusted_fps = int(fps * playback_speed)\n",
    "\n",
    "        # Display adjusted FPS on the frame\n",
    "        cv2.putText(result_frame, f\"FPS: {adjusted_fps}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        out.write(result_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ],
   "id": "1a726eafa4d591fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## **7. 메인 실행 코드**\n",
    "\n",
    "이 부분은 노트북의 메인 코드입니다. 모델을 불러오고, 비디오 파일을 처리하여 결과를 저장합니다.\n"
   ],
   "id": "d778a21ed7e7a450"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 파라미터 설정\n",
    "num_classes = 3  # 배경 + 2개의 클래스 (주차 공간, 도로)\n",
    "weights_path = \"model_weights/best_model0828.pth\"  # 저장된 모델 가중치 경로\n",
    "video_path = \"C:/088.주차 공간 탐색을 위한 차량 관점 복합 데이터/market_0.3.mp4\"  # 입력 비디오 파일 경로\n",
    "output_path = \"C:/088.주차 공간 탐색을 위한 차량 관점 복합 데이터/processed_output_market2_r.mp4\"  # 출력 비디오 파일 경로\n",
    "playback_speed = 0.3  # Video playback speed (0.3x slower)\n",
    "# 모델 로드\n",
    "model = load_model(num_classes, weights_path)\n",
    "\n",
    "# 비디오 처리 및 결과 저장\n",
    "process_video(video_path, model, output_path, playback_speed)\n",
    "\n",
    "print(f\"처리가 완료되었습니다. 결과는 {output_path}에 저장되었습니다.\")\n"
   ],
   "id": "7aff8cef8c004cf6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIHUB의 주차 공간 탐색을 위한 차량 관점 복합 데이터 전처리 과정\n",
    "\n",
    "데이터 셋은 크게 **Training Set, Validation Set**으로 나뉩니다.\n",
    "\n",
    "그리고 각각 원천 데이터 **(이미지 데이터)** 와 라벨링 데이터 **(json 파일)** 이 포함되어 있습니다.\n",
    "\n",
    "본 팀의 경우 목적은 하나의 데이터셋에서 특정한 비율로 training set과 validation set을 추출해 사용하는 것이기 때문에\n",
    "\n",
    "최대한 많은 기본 데이터셋을 확보하기 위해, 우선적으로 기존에 training과 validation으로 구분되어 있던 데이터를 하나의 데이터셋으로 통일시킵니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**[목차]**\n",
    "* **0. AIHUBSHELL 커맨드를 사용해서 원하는 Dataset 다운로드**\n",
    "* **1. 다운로드 받은 데이터셋에서 segmentation 정보를 가지고 있는 데이터만 검출**\n",
    "* **2. 팀원 각자 전처리 한 데이터 셋을 하나의 데이터 셋으로 통합**\n",
    "* **3. 전처리 된 segmentation json파일을 coco json 포맷으로 변경**\n",
    "* **4. coco dataset의 포맷으로 변경된 json 파일들을 학습에 쓰일 json파일로 하나로 통합**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. AIHUBSHELL 커맨드를 사용해서 원하는 Dataset 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 참고 : https://www.aihub.or.kr/devsport/apishell/list.do?currMenu=403&topMenu=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#주의 : 총 데이터 290.36GB 하드디스크의 여유공간을 확인하고 실행할 것.\n",
    "!aihubshell -mode d -datasetkey 598"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 다운로드 받은 데이터 셋에서 segmentation 정보를 가지고 있는 데이터만 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 로그 기록 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기록 파일 경로\n",
    "progress_file = 'progress_log.txt' # 진행 상황 저장 파일\n",
    "counter_file = 'counter_log.txt'  # 카운터(검출된 데이터 쌍의 갯수) 저장 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_files(progress_file):\n",
    "    \"\"\"이전에 처리된 파일 목록을 로드합니다.\"\"\"\n",
    "    if os.path.exists(progress_file):\n",
    "        with open(progress_file, 'r') as f:\n",
    "            processed_files = set(line.strip() for line in f)\n",
    "    else:\n",
    "        processed_files = set()\n",
    "    return processed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_file(progress_file, filename):\n",
    "    \"\"\"처리된 파일 이름을 기록합니다.\"\"\"\n",
    "    with open(progress_file, 'a') as f:\n",
    "        f.write(filename + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_counter(counter_file):\n",
    "    \"\"\"이전에 사용된 파일 카운터를 로드합니다.\"\"\"\n",
    "    if os.path.exists(counter_file):\n",
    "        with open(counter_file, 'r') as f:\n",
    "            counter = int(f.read().strip())\n",
    "    else:\n",
    "        counter = 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_counter(counter_file, counter):\n",
    "    \"\"\"파일 카운터를 저장합니다.\"\"\"\n",
    "    with open(counter_file, 'w') as f:\n",
    "        f.write(str(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 파일 맵핑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지정된 라벨링데이터(json데이터) 파일의 경로의 이름을 입력받아, 그와 매칭되는 원천데이터(이미지데이터) 이름을 리턴받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_path의 라벨데이터와 연결되어 있는 원천데이터의 경로를 반환한다\n",
    "\n",
    "def map_label_to_image_path(label_path):\n",
    "    #라벨 경로의 경로 문자열을 TL, VL을 TS, VS로, label을 Camera로 바꾼다\n",
    "    if \"TL\" in label_path:\n",
    "        return label_path.replace(\"TL\", \"TS\").replace(\"label\", \"Camera\")\n",
    "    elif \"VL\" in label_path:\n",
    "        return label_path.replace(\"VL\", \"VS\").replace(\"label\", \"Camera\")\n",
    "    # 위 조건에 맞지 않는 경우 원본 경로 그대로 반환\n",
    "    return label_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**함수 설명**\n",
    "\n",
    "* os.makedirs() : 지정한 디렉토리(경로)에 새 폴더를 생성\n",
    "* os.path.relpath(path, start) : start 경로에서 path 경로를 바라본 상대적인 경로를 계산\n",
    "* os.path.join(a, b) : a 문자열과 b 문자열을 하나로 묶어서 반환\n",
    "* os.path.normpath(path) : path 내의 ., .., // 등의 불필요한 요소를 제거 \n",
    "* os.path.exits(path) : path의 존재유무에 True, False 반환\n",
    "\n",
    "* **os.walk(path) : 주어진 path의 하위 폴더와 파일을 탐색하는 함수**\n",
    "\n",
    "    * subdir : ./test/ 아래의 모든 폴더의 경로 리스트 반환\n",
    "    * _ : subdir 경로에 하위 폴더가 또 있는 경우 그 폴더 경로의 리스트 반환\n",
    "    * files : subdir 경로의 하위 파일 경로를 리스트로 반환\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segmented_data(label_root_dir, image_root_dir, output_json_dir, output_image_dir, progress_file,\n",
    "                           counter_file):\n",
    "    \"\"\"라벨링 데이터와 원천 데이터를 각각 탐색하여 JSON과 이미지 파일을 매칭합니다.\"\"\"\n",
    "\n",
    "    # 이전에 처리된 파일 목록을 로드합니다.\n",
    "    processed_files = load_processed_files(progress_file)\n",
    "\n",
    "    # 이전 카운터를 로드합니다.\n",
    "    file_counter = load_counter(counter_file)\n",
    "\n",
    "    # 출력 디렉토리가 존재하지 않으면 생성합니다.\n",
    "    os.makedirs(output_json_dir, exist_ok=True)\n",
    "    os.makedirs(output_image_dir, exist_ok=True)\n",
    "\n",
    "    # 라벨링 데이터 디렉토리를 순회하며 JSON 파일을 찾습니다.\n",
    "    for subdir, _, files in os.walk(label_root_dir):\n",
    "        for json_file in files:\n",
    "            if json_file.endswith(\".json\"):\n",
    "                json_path = os.path.join(subdir, json_file)\n",
    "\n",
    "                # 이미 처리된 파일은 건너뜁니다.\n",
    "                if json_path in processed_files:\n",
    "                    continue\n",
    "\n",
    "                with open(json_path, \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                if \"segmentation\" in data and data[\"segmentation\"]:\n",
    "                    # 대응하는 이미지 파일 경로 생성\n",
    "                    relative_path = os.path.relpath(json_path, label_root_dir)\n",
    "                    mapped_relative_path = map_label_to_image_path(relative_path)\n",
    "                    image_path = os.path.join(image_root_dir, mapped_relative_path.replace(\".json\", \".jpg\"))\n",
    "                    image_path = os.path.normpath(image_path)  # 경로 정규화\n",
    "\n",
    "                    # 이미지 파일이 존재하는 경우에만 JSON과 이미지를 복사합니다.\n",
    "                    if os.path.exists(image_path):\n",
    "                        new_json_name = f\"image_{file_counter}.json\"\n",
    "                        new_img_name = f\"image_{file_counter}.jpg\"\n",
    "\n",
    "                        shutil.copy(json_path, os.path.join(output_json_dir, new_json_name))\n",
    "                        shutil.copy(image_path, os.path.join(output_image_dir, new_img_name))\n",
    "\n",
    "                        # 파일 처리 후 진행 상태를 기록합니다.\n",
    "                        save_processed_file(progress_file, json_path)\n",
    "\n",
    "                        # 카운터 증가 및 저장\n",
    "                        file_counter += 1\n",
    "                        save_counter(counter_file, file_counter)\n",
    "                    else:\n",
    "                        print(f\"이미지 {image_path}를 찾을 수 없어서 JSON 파일 {json_file}과 연관된 파일을 건너뜁니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세부 설명\n",
    "* 라벨데이터와 원천데이터 경로를 입력합니다\n",
    "* segmentation 정보를 기준으로 전처리 된 데이터의 반환 경로를 입력합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json 파일 내부에 segmentation 정보가 있는 json과 그에 연결되는 이미지를 지정된 경로에 복사\n",
    "label_root_dir = r'C:\\Users\\TRUENEAT0223\\Documents\\vscode\\project01_local\\2.Validation\\라벨링데이터'  # 라벨링 데이터 루트 디렉토리\n",
    "image_root_dir = r'C:\\Users\\TRUENEAT0223\\Documents\\vscode\\project01_local\\2.Validation\\원천데이터'  # 원천 데이터 루트 디렉토리\n",
    "output_json_dir = r'C:\\Users\\TRUENEAT0223\\Documents\\vscode\\project01_local\\segmentjson'  # 출력 JSON 파일 디렉토리\n",
    "output_image_dir = r'C:\\Users\\TRUENEAT0223\\Documents\\vscode\\project01_local\\segmentimage'  # 출력 이미지 파일 디렉토리\n",
    "\n",
    "extract_segmented_data(label_root_dir, image_root_dir, output_json_dir, output_image_dir, progress_file, counter_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 팀원 각자 전처리 한 데이터셋을 하나의 데이터셋으로 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세부 설명\n",
    "* 병합된 json 파일들과 image 파일들의 디렉토리의 경로를 입력합니다\n",
    "* 병합할 json 파일들과 image 파일들의 팀원 각각의 경로를 입력합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병합될 디렉토리 경로\n",
    "merged_json_dir = \"/home/elicer/merged_data/merged_segmentjson\"\n",
    "merged_image_dir = \"/home/elicer/merged_data/merged_segmentimage\"\n",
    "\n",
    "\n",
    "# 동료별 디렉토리 설정(인원 수에 따라 딕셔너리 키, 밸류 값 제거 가능)\n",
    "collab_dirs = {\n",
    "    \"MSB\": {\n",
    "        \"json_dir\": \"/home/elicer/MSB/segmentjson\",\n",
    "        \"image_dir\": \"/home/elicer/MSB/segmentimage\"\n",
    "    },\n",
    "    \"KSH\": {\n",
    "        \"json_dir\": \"/home/elicer/KSH/segmentjson\",\n",
    "        \"image_dir\": \"/home/elicer/KSH/segmentimage\"\n",
    "    },\n",
    "    \"LYJ\": {\n",
    "        \"json_dir\": \"/home/elicer/LYJ/segmentjson\",\n",
    "        \"image_dir\": \"/home/elicer/LYJ/segmentimage\"\n",
    "    },\n",
    "    \"BDN\": {\n",
    "        \"json_dir\": \"/home/elicer/LYJ/segmentjson\",\n",
    "        \"image_dir\": \"/home/elicer/LYJ/segmentimage\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 설명\n",
    "* 병합 데이터가 모일 디렉토리 내에서 가장 큰 넘버를 return 하는 함수입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_number(directory, extension):\n",
    "    \n",
    "    max_num = 0\n",
    "    pattern = re.compile(r'image_(\\d+)\\.' + extension)  # 숫자를 포함하는 패턴 찾기\n",
    "    for filename in os.listdir(directory):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            num = int(match.group(1))\n",
    "            if num > max_num:\n",
    "                max_num = num\n",
    "    return max_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 설명\n",
    "* 병합 데이터가 모일 디렉토리에 있는 파일을 카운팅하고, 가장 큰 넘버 이후의 넘버로 데이터 복사합니다\n",
    "\n",
    "* 예시) 마석빈 : 1, 2, 3  김서희 : 1, 2, 3    박달님 : 1, 2, 3    이윤제 : 1, 2, 3    =>  병합 데이터 : 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병합 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(merged_json_dir, exist_ok=True)\n",
    "os.makedirs(merged_image_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# 기존 데이터에서 가장 큰 번호 찾기\n",
    "current_max_num = max(\n",
    "    get_last_number(merged_json_dir, \"json\"),\n",
    "    get_last_number(merged_image_dir, \"jpg\")\n",
    ")\n",
    "\n",
    "\n",
    "# 동료들의 파일을 병합\n",
    "for collab, dirs in collab_dirs.items():\n",
    "    json_dir = dirs['json_dir']\n",
    "    image_dir = dirs['image_dir']\n",
    "\n",
    "    json_files = [f for f in os.listdir(json_dir) if f.endswith(\".json\")]\n",
    "    for json_file in json_files:\n",
    "        # JSON 파일과 대응되는 이미지 파일 이름 구하기\n",
    "        image_file = json_file.replace(\".json\", \".jpg\")\n",
    "\n",
    "        json_path = os.path.join(json_dir, json_file)\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "        # 이미지와 JSON 파일이 모두 존재하는지 확인\n",
    "        if os.path.exists(image_path):\n",
    "            current_max_num += 1\n",
    "            new_json_name = f\"image_{current_max_num}.json\"\n",
    "            new_image_name = f\"image_{current_max_num}.jpg\"\n",
    "\n",
    "            # 파일 복사\n",
    "            new_json_path = os.path.join(merged_json_dir, new_json_name)\n",
    "            new_image_path = os.path.join(merged_image_dir, new_image_name)\n",
    "\n",
    "            shutil.copy(json_path, new_json_path)\n",
    "            shutil.copy(image_path, new_image_path)\n",
    "        else:\n",
    "            print(f\"이미지 {image_file}를 찾을 수 없어서 JSON 파일 {json_file}과 연관된 파일을 건너뜁니다.\")\n",
    "\n",
    "print(\"모든 파일이 병합되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 전처리 된 segmentation json파일을 coco json 포맷으로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 설명\n",
    "* segmentation 영역의 넓이를 계산합니다\n",
    "\n",
    "    Shoelace formula : 신발끈 공식으로 불리며, 좌표평면상 점의 좌표를 이용하여 다각형의 넓이를 계산하는 공식입니다. \n",
    "\n",
    "    |x1 * y2 + x2 * y3 + ... + xn * y1) + (y1 * x2 - y2 * x3 - ... - yn * x1| / 2\n",
    "\n",
    "* segmentation 폴리곤들의 최소점 x, y와 최대점 x, y를 구해서 가장 넓은 bounding box 를 구합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 된 json파일에서 segmentation 넓이 계산\n",
    "def calculate_area(polygon):\n",
    "    #1차원 polygon 리스트의 자표를 2칸씩 건너뛰며 x, y좌표를 받아오기\n",
    "    x = np.array(polygon[::2])\n",
    "    y = np.array(polygon[1::2])\n",
    "\n",
    "    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n",
    "\n",
    "\n",
    "# 전처리 된 json파일에서 segmentation을 기준으로 최대 bbox 계산\n",
    "def calculate_bbox(polygon):\n",
    "    x = polygon[::2]\n",
    "    y = polygon[1::2]\n",
    "\n",
    "    return [min(x), min(y), max(x) - min(x), max(y) - min(y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세부 설명\n",
    "* aihub 데이터셋의 json 과 coco 데이터 포맷 json의 차이점은, segmentation의 영역을 지정할 때 사용하는 polygon을 2차원 배열로 배치하느냐 1차원 배열로 배치하느냐의 차이입니다.\n",
    "* 2차원 배열로 [x1, y1], [x2, y2], ... 로 저장되어 있는 segmentation polygon 정보를 [x1, y1, x2, y2, ...] 형태로 풀어 저장합니다.\n",
    "\n",
    "함수 설명\n",
    "* coco라는 딕셔너리를 하나 만듭니다.\n",
    "*  기존 segmentation 전처리 파일에서 연결되는 이미지, annotations, categories 정보를 가져와 coco에 입력합니다. \n",
    "* 이후 json.dump() 함수를 사용해 새로운 coco 데이터 포맷 json 파일을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_coco(input_json_path, image_dir, output_dir):\n",
    "\n",
    "    # 전처리된 json 파일 내용을 data에 입력\n",
    "    with open(input_json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "\n",
    "    #input_json_path 라벨 이름 문자열에서 .json을 .jpg로 바꿔 이미지 이름으로 사용\n",
    "    img_filename = os.path.basename(input_json_path).replace(\".json\", \".jpg\")\n",
    "\n",
    "    # 이미지 크기 고정 (1920x1080)\n",
    "    width = 1920\n",
    "    height = 1080\n",
    "\n",
    "\n",
    "    # 틀이 되는 coco 포맷 딕셔너리\n",
    "    coco = {\n",
    "        \"images\": [{\n",
    "            \"id\": 0,\n",
    "            \"file_name\": img_filename, # 연결될 이미지 이름 저장\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        }],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [\n",
    "            {\"id\": 1, \"name\": \"Parking Space\"},\n",
    "            {\"id\": 2, \"name\": \"Driveable Space\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    annotation_id = 0\n",
    "    category_id_map = {cat['name']: cat['id'] for cat in coco['categories']}\n",
    "\n",
    "    # 세그멘테이션 어노테이션 추가\n",
    "    for segmentation in data.get(\"segmentation\", []):\n",
    "\n",
    "        # 전처리된 json파일에서 카테고리 이름 저장\n",
    "        category_name = segmentation[\"name\"]\n",
    "        if category_name not in category_id_map:\n",
    "            continue  # 'Parking Space'나 'Driveable Space'가 아니면 무시\n",
    "\n",
    "        \n",
    "        #'Parking Space'나 'Driveable Space'라면 그에 맞는 id 저장\n",
    "        category_id = category_id_map[category_name]\n",
    "\n",
    "\n",
    "        # 폴리곤 좌표를 1차원 리스트로 변환\n",
    "        # polygon은 segmentation 영역의 좌표를 1차원 리스트에 풀어낸 것\n",
    "        polygon = [coord for point in segmentation[\"polygon\"] for coord in point]\n",
    "\n",
    "\n",
    "        # annotation값을 정리해 딕셔너리에 입력\n",
    "        annotation = {\n",
    "            \"id\": annotation_id,\n",
    "            \"image_id\": 0,\n",
    "            \"category_id\": category_id,\n",
    "            \"segmentation\": [polygon],\n",
    "            \"area\": calculate_area(polygon),\n",
    "            \"bbox\": calculate_bbox(polygon),\n",
    "            \"iscrowd\": 0\n",
    "        }\n",
    "\n",
    "        # 틀이 되는 coco 포맷의 annotations 항목에 annotation 딕셔너리 저장\n",
    "        coco[\"annotations\"].append(annotation)\n",
    "        annotation_id += 1\n",
    "\n",
    "    # 파일명 생성 및 저장\n",
    "    output_filename = os.path.basename(input_json_path).replace(\".json\", \"_coco.json\")\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "\n",
    "    # 정보를 전부 입력받은 coco 딕셔너리를 새로운 _coco.json 파일에 저장\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(coco, f, indent=4) #indent=4 : 4개의 공백으로 들여쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 입력\n",
    "\n",
    "input_json_dir = \"/home/elicer/merged_data/merged_segmentjson\"  # JSON 파일들이 있는 디렉토리\n",
    "image_dir = \"/home/elicer/merged_data/merged_segmentimage\"  # 이미지 파일들이 있는 디렉토리\n",
    "output_dir = \"/home/elicer/merged_data/merged_coco_files\"  # COCO 포맷으로 저장할 디렉토리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 실행\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_json_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        convert_json_to_coco(os.path.join(input_json_dir, filename), image_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. coco dataset의 포맷으로 변경된 json 파일들을 학습에 쓰일 json파일로 하나로 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* coco 포맷 데이터들을 하나의 coco 포맷 데이터로 합치는 것\n",
    "\n",
    "예) image_1_coco.json, image_2_coco.json, image_3_coco.json, ... image_n_coco.json =>  merged_coco.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 설명\n",
    "* merged_coco 라는 딕셔너리를 생성합니다.\n",
    "* 새롭게 정립할 id를 annotation_id = 1, image_id = 1로 초기화 시킵니다.\n",
    "* 이하 for문은 중복되는 categories, images, annotations 데이터를 새로운 id를 기준으로 중복 없이 merged_coco에 넣는 과정입니다.\n",
    "* for문이 끝난 후, json.dump() 함수를 사용해 하나의 큰 coco 데이터 포맷의 json파일을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_coco_jsons(input_dir, output_file):\n",
    "    #큰 틀의 image, annotations, categories 딕셔너리\n",
    "    merged_coco = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "\n",
    "    # id 초기화에 필요한 id 시작 값\n",
    "    annotation_id = 1\n",
    "    image_id = 1\n",
    "    category_map = {}\n",
    "\n",
    "    # input_dir에 있는 파일 하나를 filename으로 받기\n",
    "    for filename in os.listdir(input_dir):\n",
    "        # filename의 어미에 _coco.json이 있는가?(coco 포맷 json 파일인가?)\n",
    "        if filename.endswith(\"_coco.json\"):\n",
    "            # coco json 파일을 열어서 값을 coco_data에 저장\n",
    "            with open(os.path.join(input_dir, filename), 'r', encoding='utf-8') as f:\n",
    "                coco_data = json.load(f)\n",
    "\n",
    "                # 각 파일의 categories 섹션을 탐색하며, 새로운 카테고리가 있을 경우 category_map에 추가합니다. 이후 값을 merged_coco에 추가합니다.\n",
    "                for category in coco_data['categories']:\n",
    "                    if category['id'] not in category_map:   \n",
    "                        category_map[category['id']] = len(category_map) + 1    \n",
    "                        category['id'] = category_map[category['id']]\n",
    "                        merged_coco['categories'].append(category)                  \n",
    "\n",
    "                # 각 파일의 images 섹션에서 이미지를 하나씩 읽어 image_id를 새로운 ID로 재지정합니다. 이후 값을 merged_coco에 추가합니다.\n",
    "                for image in coco_data['images']:       \n",
    "                    image['id'] = image_id\n",
    "                    merged_coco['images'].append(image)\n",
    "                    image_id += 1\n",
    "\n",
    "                # 각 파일의 annotations 섹션에서 어노테이션을 하나씩 읽은 후 새로운 annotation_id를 부여, 어노테이션의 image_id도 통합된 이미지의 ID와 일치하도록 업데이트합니다.\n",
    "                for annotation in coco_data['annotations']:\n",
    "                    annotation['id'] = annotation_id\n",
    "                    annotation['image_id'] = image_id - 1\n",
    "                    annotation['category_id'] = category_map[annotation['category_id']]\n",
    "                    merged_coco['annotations'].append(annotation)\n",
    "                    annotation_id += 1\n",
    "\n",
    "    # 위의 merged_coco 딕셔너리를 json 파일로 가공\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(merged_coco, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세부 설명\n",
    "* input_dir에 통합시킬 coco 데이터 포맷 json 폴더 경로를, output_file에 병합된 파일이 저장될 위치를 입력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dir = '/home/elicer/merged_data/merged_coco_files'          # 통합시킬 coco 포맷 json 디렉토리\n",
    "output_file = '/home/elicer/merged_data/merged_coco.json'   # 통합된 merge_coco.json 파일을 넣을 디렉토리 \n",
    "\n",
    "merge_coco_jsons(input_dir, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
